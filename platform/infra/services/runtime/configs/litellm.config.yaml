# SPDX-License-Identifier: LicenseRef-PolyForm-Shield-1.0.0
# SPDX-FileCopyrightText: 2025 Cogni-DAO

# LiteLLM Proxy Configuration
# Purpose: Model routing configuration for LiteLLM proxy with OpenRouter models
# Scope: Defines model aliases, provider routing (openrouter/ prefix), and database settings
# Notes: All models route through OpenRouter; free tier models may hit rate limits without API key
# Links: https://docs.litellm.ai/docs/providers/openrouter

model_list:
  # ===== FREE MODELS =====
  # Validated for streaming + tool support (2026-01-28)
  # Rate limits: 50 req/day (free plan) or 1000 req/day (>=$10 credits)

  # NVIDIA
  - model_name: nemotron-nano-30b
    litellm_params:
      model: openrouter/nvidia/nemotron-3-nano-30b-a3b:free
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "Nemotron Nano 30B"
      is_free: true
      provider_key: "nvidia"
      metadata:
        cogni:
          default_free: true

  # Arcee
  - model_name: trinity-mini
    litellm_params:
      model: openrouter/arcee-ai/trinity-mini:free
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "Trinity Mini"
      is_free: true
      provider_key: "arcee"

  # Zhipu (GLM)
  - model_name: glm-4.5-air
    litellm_params:
      model: openrouter/z-ai/glm-4.5-air:free
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "GLM 4.5 Air"
      is_free: true
      provider_key: "zhipu"

  # Upstage
  - model_name: solar-pro-3
    litellm_params:
      model: openrouter/upstage/solar-pro-3:free
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "Solar Pro 3"
      is_free: true
      provider_key: "upstage"

  # ===== PAID MODELS =====
  # OpenAI
  - model_name: gpt-4o-mini
    litellm_params:
      model: openrouter/openai/gpt-4o-mini-2024-07-18
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "GPT-4o Mini"
      is_free: false
      provider_key: "openai"

  - model_name: gpt-5
    litellm_params:
      model: openrouter/openai/gpt-5
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "GPT-5"
      is_free: false
      provider_key: "openai"

  # Anthropic (ZDR-enabled: Zero Data Retention - provider won't log/train on data)
  - model_name: claude-sonnet-4.5
    litellm_params:
      model: openrouter/anthropic/claude-sonnet-4.5
      api_key: "os.environ/OPENROUTER_API_KEY"
      extra_body:
        provider:
          zdr: true
      # OpenRouter prompt caching (Anthropic): requires cache_control breakpoints.
      # Inject markers automatically so callers (e.g. OpenClaw) donâ€™t need to emit
      # multipart content blocks explicitly.
      #
      # NOTE: This injects `{cache_control:{type:"ephemeral"}}` (OpenRouter default TTL ~5m).
      # For 1h TTL, the caller must send `ttl:"1h"` in cache_control.
      cache_control_injection_points:
        - location: message
          role: system
    model_info:
      display_name: "Claude Sonnet 4.5"
      is_free: false
      is_zdr: true
      provider_key: "anthropic"

  - model_name: claude-opus-4.5
    litellm_params:
      model: openrouter/anthropic/claude-opus-4.5
      api_key: "os.environ/OPENROUTER_API_KEY"
      extra_body:
        provider:
          zdr: true
      # OpenRouter prompt caching (Anthropic): auto-inject cache_control breakpoints.
      cache_control_injection_points:
        - location: message
          role: system
    model_info:
      display_name: "Claude Opus 4.5"
      is_free: false
      is_zdr: true
      provider_key: "anthropic"

  # DeepSeek
  - model_name: deepseek-v3.1
    litellm_params:
      model: openrouter/deepseek/deepseek-chat-v3.1
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "DeepSeek V3.1"
      is_free: false
      provider_key: "deepseek"

  # Google (ZDR-enabled: Zero Data Retention)
  - model_name: gemini-2.5-flash
    litellm_params:
      model: openrouter/google/gemini-2.5-flash
      api_key: "os.environ/OPENROUTER_API_KEY"
      extra_body:
        provider:
          zdr: true
      # OpenRouter prompt caching (Gemini/OpenRouter): cache_control breakpoints can
      # increase cache hit rate when the prefix is stable.
      cache_control_injection_points:
        - location: message
          role: system
    model_info:
      display_name: "Gemini 2.5 Flash"
      is_free: false
      is_zdr: true
      provider_key: "google"
      metadata:
        cogni:
          default_preferred: true

  - model_name: gemini-3-pro
    litellm_params:
      model: openrouter/google/gemini-3-pro-preview
      api_key: "os.environ/OPENROUTER_API_KEY"
      extra_body:
        provider:
          zdr: true
      cache_control_injection_points:
        - location: message
          role: system
    model_info:
      display_name: "Gemini 3 Pro"
      is_free: false
      is_zdr: true
      provider_key: "google"

  - model_name: gemini-3-flash
    litellm_params:
      model: openrouter/google/gemini-3-flash-preview
      api_key: "os.environ/OPENROUTER_API_KEY"
      extra_body:
        provider:
          zdr: true
      cache_control_injection_points:
        - location: message
          role: system
    model_info:
      display_name: "Gemini 3 Flash"
      is_free: false
      is_zdr: true
      provider_key: "google"

  # Kimi (MoonshotAI)
  - model_name: kimi-k2-thinking
    litellm_params:
      model: openrouter/moonshotai/kimi-k2-thinking
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "Kimi K2 Thinking"
      is_free: false
      provider_key: "kimi"

  # Minimax
  - model_name: minimax-m2
    litellm_params:
      model: openrouter/minimax/minimax-m2
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "Minimax M2"
      is_free: false
      provider_key: "minimax"

  # Qwen
  - model_name: qwen3-vl-8b
    litellm_params:
      model: openrouter/qwen/qwen3-vl-8b-thinking
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "Qwen 3 VL 8B"
      is_free: false
      provider_key: "qwen"

  # XAI (Grok)
  - model_name: grok-4.1-fast
    litellm_params:
      model: openrouter/x-ai/grok-4.1-fast
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "Grok 4.1 Fast"
      is_free: false
      provider_key: "xai"

  # ===== EMBEDDING MODELS =====
  # Used by OpenClaw memory_search for semantic vector search
  # Uses openai/ prefix + api_base to avoid openrouter/ embedding routing bugs (BerriAI/litellm#19016)
  - model_name: text-embedding-3-small
    litellm_params:
      model: openai/text-embedding-3-small
      api_base: https://openrouter.ai/api/v1
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "Text Embedding 3 Small"
      is_free: false
      provider_key: "openrouter"

litellm_settings:
  include_cost_in_streaming_usage: true
  success_callback: ["langfuse", "generic_api"]
  failure_callback: ["langfuse"]

general_settings:
  master_key: "os.environ/LITELLM_MASTER_KEY"
  database_url: "os.environ/LITELLM_DATABASE_URL"
  database_type: "postgres"
