# SPDX-License-Identifier: LicenseRef-PolyForm-Shield-1.0.0
# SPDX-FileCopyrightText: 2025 Cogni-DAO

# LiteLLM Proxy Configuration
# Purpose: Model routing configuration for LiteLLM proxy with OpenRouter models
# Scope: Defines model aliases, provider routing (openrouter/ prefix), and database settings
# Notes: All models route through OpenRouter; free tier models may hit rate limits without API key
# Links: https://docs.litellm.ai/docs/providers/openrouter

model_list:
  # ===== FREE MODEL =====
  # gpt-4o-mini designated as the default free model for cost control
  # Note: 4o-mini is NOT actually free... we are making it available, so free tier users can use it.
  # All other models are paid and require explicit selection
  - model_name: gpt-4o-mini
    litellm_params:
      model: openrouter/openai/gpt-4o-mini-2024-07-18
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "GPT-4o Mini"
      is_free: true
      provider_key: "openai"
      metadata:
        cogni:
          default_free: true

  # ===== PAID MODELS =====
  # DeepSeek
  - model_name: deepseek-v3.2
    litellm_params:
      model: openrouter/deepseek/deepseek-v3.2
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "DeepSeek V3.2"
      is_free: false
      provider_key: "deepseek"
      metadata:
        cogni:
          default_thinking: true

  - model_name: kimi-k2.5
    litellm_params:
      model: openrouter/moonshotai/kimi-k2.5
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "Kimi K2.5"
      is_free: false
      provider_key: "kimi"
      metadata:
        cogni:
          fallback_thinking: true

  # Minimax
  - model_name: minimax-m2
    litellm_params:
      model: openrouter/minimax/minimax-m2
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "Minimax M2"
      is_free: false
      provider_key: "minimax"

  - model_name: gpt-5.2
    litellm_params:
      model: openrouter/openai/gpt-5.2
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "GPT-5.2"
      is_free: false
      provider_key: "openai"

  - model_name: gpt-5
    litellm_params:
      model: openrouter/openai/gpt-5
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "GPT-5"
      is_free: false
      provider_key: "openai"

  # Anthropic (ZDR-enabled: Zero Data Retention - provider won't log/train on data)
  - model_name: claude-sonnet-4.5
    litellm_params:
      model: openrouter/anthropic/claude-sonnet-4.5
      api_key: "os.environ/OPENROUTER_API_KEY"
      extra_body:
        provider:
          zdr: true
      # OpenRouter prompt caching (Anthropic): requires cache_control breakpoints.
      # Inject markers automatically so callers (e.g. OpenClaw) donâ€™t need to emit
      # multipart content blocks explicitly.
      #
      # NOTE: This injects `{cache_control:{type:"ephemeral"}}` (OpenRouter default TTL ~5m).
      # For 1h TTL, the caller must send `ttl:"1h"` in cache_control.
      cache_control_injection_points:
        - location: message
          role: system
    model_info:
      display_name: "Claude Sonnet 4.5"
      is_free: false
      is_zdr: true
      provider_key: "anthropic"

  - model_name: claude-opus-4.5
    litellm_params:
      model: openrouter/anthropic/claude-opus-4.5
      api_key: "os.environ/OPENROUTER_API_KEY"
      extra_body:
        provider:
          zdr: true
      # OpenRouter prompt caching (Anthropic): auto-inject cache_control breakpoints.
      cache_control_injection_points:
        - location: message
          role: system
    model_info:
      display_name: "Claude Opus 4.5"
      is_free: false
      is_zdr: true
      provider_key: "anthropic"

  - model_name: deepseek-v3.1
    litellm_params:
      model: openrouter/deepseek/deepseek-v3.1
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "DeepSeek V3.1"
      is_free: false
      provider_key: "deepseek"

  # Google (ZDR-enabled: Zero Data Retention)
  - model_name: gemini-2.5-flash
    litellm_params:
      model: openrouter/google/gemini-2.5-flash
      api_key: "os.environ/OPENROUTER_API_KEY"
      extra_body:
        provider:
          zdr: true
      # OpenRouter prompt caching (Gemini/OpenRouter): cache_control breakpoints can
      # increase cache hit rate when the prefix is stable.
      cache_control_injection_points:
        - location: message
          role: system
    model_info:
      display_name: "Gemini 2.5 Flash"
      is_free: false
      is_zdr: true
      provider_key: "google"

  - model_name: gemini-3-pro
    litellm_params:
      model: openrouter/google/gemini-3-pro-preview
      api_key: "os.environ/OPENROUTER_API_KEY"
      extra_body:
        provider:
          zdr: true
      cache_control_injection_points:
        - location: message
          role: system
    model_info:
      display_name: "Gemini 3 Pro"
      is_free: false
      is_zdr: true
      provider_key: "google"

  - model_name: gemini-3-flash
    litellm_params:
      model: openrouter/google/gemini-3-flash-preview
      api_key: "os.environ/OPENROUTER_API_KEY"
      extra_body:
        provider:
          zdr: true
      cache_control_injection_points:
        - location: message
          role: system
    model_info:
      display_name: "Gemini 3 Flash"
      is_free: false
      is_zdr: true
      provider_key: "google"

  # Kimi (MoonshotAI)
  - model_name: kimi-k2-thinking
    litellm_params:
      model: openrouter/moonshotai/kimi-k2-thinking
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "Kimi K2 Thinking"
      is_free: false
      provider_key: "kimi"

  # Qwen
  - model_name: qwen3-vl-8b
    litellm_params:
      model: openrouter/qwen/qwen3-vl-8b-thinking
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "Qwen 3 VL 8B"
      is_free: false
      provider_key: "qwen"

  # XAI (Grok)
  - model_name: grok-4.1-fast
    litellm_params:
      model: openrouter/x-ai/grok-4.1-fast
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "Grok 4.1 Fast"
      is_free: false
      provider_key: "xai"

  # Meta (Llama)
  - model_name: llama-3.3-70b
    litellm_params:
      model: openrouter/meta-llama/llama-3.3-70b-instruct
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "Llama 3.3 70B"
      is_free: false
      provider_key: "meta"
      metadata:
        cogni:
          default_flash: true

  # ===== EMBEDDING MODELS =====
  # Used by OpenClaw memory_search for semantic vector search
  # Uses openai/ prefix + api_base to avoid openrouter/ embedding routing bugs (BerriAI/litellm#19016)
  - model_name: text-embedding-3-small
    litellm_params:
      model: openai/text-embedding-3-small
      api_base: https://openrouter.ai/api/v1
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      display_name: "Text Embedding 3 Small"
      is_free: false
      provider_key: "openrouter"

litellm_settings:
  drop_params: true
  include_cost_in_streaming_usage: true
  success_callback: ["langfuse", "generic_api"]
  failure_callback: ["langfuse"]

general_settings:
  master_key: "os.environ/LITELLM_MASTER_KEY"
  database_url: "os.environ/LITELLM_DATABASE_URL"
  database_type: "postgres"
