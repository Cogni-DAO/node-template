// SPDX-License-Identifier: LicenseRef-PolyForm-Shield-1.0.0
// SPDX-FileCopyrightText: 2025 Cogni-DAO

/**
 * Module: `@app/_facades/ai/completion.server`
 * Purpose: App-layer coordinator for AI completion - session → billing account, delegates to feature layer.
 * Scope: Resolves session user to billing account + virtual key, creates LlmCaller, maps DTOs, normalizes errors. Does not contain business logic or HTTP concerns.
 * Invariants:
 *   - UNIFIED_GRAPH_EXECUTOR: Both completion() and completionStream() use GraphExecutorPort
 *   - Only app layer imports this; routes call this, not features/* directly
 *   - Must import features via public.ts ONLY (never import from services subdirectories)
 *   - NEVER import adapters (use bootstrap factories instead)
 *   - Per CREDITS_ENFORCED_AT_EXECUTION_PORT: preflight credit check handled by decorator (no facade-level call)
 *   - Validates billing account before delegation; propagates feature errors
 * Side-effects: IO (via resolved dependencies)
 * Notes: completion() delegates to completionStream() and collects response server-side
 * Links: Called by API routes, delegates to features/ai/public.ts, GRAPH_EXECUTION.md
 * @public
 */

import { createHash } from "node:crypto";
import { toUserId } from "@cogni/ids";
import type { z } from "zod";
import { resolveAiAdapterDeps } from "@/bootstrap/container";
import { createGraphExecutor } from "@/bootstrap/graph-executor.factory";
import type { aiCompletionOperation } from "@/contracts/ai.completion.v1.contract";
import { mapAccountsPortErrorToFeature } from "@/features/accounts/public";
// Types from client-safe barrel (types only, no runtime)
import type { AiEvent, StreamFinalResult } from "@/features/ai/public";
// Import from public.server.ts - never from services/* directly (dep-cruiser enforced)
import {
  createAiRuntime,
  executeStream,
  type MessageDto,
  preflightCreditCheck,
  toCoreMessages,
} from "@/features/ai/public.server";
import { getOrCreateBillingAccountForUser } from "@/lib/auth/mapping";
import type { LlmCaller, PreflightCreditCheckFn } from "@/ports";
import {
  isBillingAccountNotFoundPortError,
  isInsufficientCreditsPortError,
  isVirtualKeyNotFoundPortError,
} from "@/ports";
import type { SessionUser } from "@/shared/auth";
import type { RequestContext } from "@/shared/observability";

interface CompletionInput {
  messages: MessageDto[];
  model: string;
  sessionUser: SessionUser;
  /** Graph name or fully-qualified graphId to execute (required) */
  graphName: string;
  /**
   * Conversation state key for multi-turn conversations.
   * If absent, server generates one.
   */
  stateKey?: string;
}

// Type-level enforcement: facade MUST return exact contract shape
type CompletionOutput = z.infer<typeof aiCompletionOperation.output>;

/**
 * Derive Langfuse sessionId from billingAccountId + stateKey.
 * Uses SHA-256 hash to ensure:
 * - Deterministic: same inputs → same sessionId (stable grouping)
 * - Bounded: fixed output length regardless of stateKey length
 * - Safe: no PII or log-injection risk from raw stateKey
 *
 * Format: `ba:{billingAccountId}:s:{sha256(stateKey)[0:32]}`
 * Truncation to 200 chars happens at Langfuse sink boundary.
 */
function deriveSessionId(billingAccountId: string, stateKey: string): string {
  const stateKeyHash = createHash("sha256")
    .update(stateKey)
    .digest("hex")
    .slice(0, 32);
  return `ba:${billingAccountId}:s:${stateKeyHash}`;
}

/**
 * Non-streaming AI completion.
 * Per UNIFIED_GRAPH_EXECUTOR: delegates to completionStream() and collects response server-side.
 * This ensures billing flows through GraphExecutorPort → RunEventRelay → commitUsageFact().
 */
export async function completion(
  input: CompletionInput,
  ctx: RequestContext
): Promise<CompletionOutput> {
  const userId = toUserId(input.sessionUser.id);
  const { clock } = resolveAiAdapterDeps(userId);

  // Delegate to streaming path (UNIFIED_GRAPH_EXECUTOR)
  const { stream, final } = await completionStream(input, ctx);

  // Collect text deltas server-side
  // Errors (including InsufficientCreditsPortError from preflight) occur lazily during consumption
  // Both stream consumption AND final await are wrapped - final can reject after loop completes
  const textParts: string[] = [];
  try {
    for await (const event of stream) {
      if (event.type === "text_delta") {
        textParts.push(event.delta);
      }
      // done event signals end of stream; billing already handled by RunEventRelay
      // Note: errors are thrown as exceptions, not emitted as events
    }

    // Await final to ensure billing completed via RunEventRelay
    const result = await final;

    if (!result.ok) {
      // Preflight handles insufficient_credits before execution starts.
      // Any error here is from graph execution itself.
      throw new Error(`Completion failed: ${result.error}`);
    }

    // Build response in contract format
    const content = textParts.join("");
    const timestamp = clock.now();

    return {
      message: {
        role: "assistant",
        content,
        timestamp,
        requestId: result.requestId,
      },
    };
  } catch (error) {
    // Map port-level errors to feature errors for route handler.
    // Port errors arrive lazily from the decorator via stream iteration.
    // Route layer handles AccountsFeatureError via isAccountsFeatureError() → 402/403.
    if (
      isInsufficientCreditsPortError(error) ||
      isBillingAccountNotFoundPortError(error) ||
      isVirtualKeyNotFoundPortError(error)
    ) {
      throw mapAccountsPortErrorToFeature(error);
    }
    throw error;
  }
}

/**
 * Stream chat completion via AI streaming service.
 * App facade responsibility: session → billing account, caller creation, error mapping.
 * NO business logic here - delegates to feature layer via public.ts.
 */
export async function completionStream(
  input: CompletionInput & { abortSignal?: AbortSignal },
  ctx: RequestContext
): Promise<{
  stream: AsyncIterable<AiEvent>;
  final: Promise<StreamFinalResult>;
}> {
  // Parse once at edge — single branded UserId for all downstream calls
  const userId = toUserId(input.sessionUser.id);

  // Per UNIFIED_GRAPH_EXECUTOR: use bootstrap factory (app → bootstrap → adapters)
  // Facade CANNOT import adapters - architecture boundary enforced by depcruise
  // Per PROVIDER_AGGREGATION: AggregatingGraphExecutor routes by graphId to providers
  const { accountService, clock } = resolveAiAdapterDeps(userId);

  // Create preflight credit check closure (app layer → features DI boundary)
  // Per CREDITS_ENFORCED_AT_EXECUTION_PORT: decorator handles all execution paths
  const preflightCheckFn: PreflightCreditCheckFn = (
    billingAccountId,
    model,
    messages
  ) =>
    preflightCreditCheck({
      billingAccountId,
      messages: [...messages],
      model,
      accountService,
    });

  // Create graph executor via bootstrap factory
  // Routing is handled by AggregatingGraphExecutor - facade is graph-agnostic
  const graphExecutor = createGraphExecutor(
    executeStream,
    userId,
    preflightCheckFn
  );

  const billingAccount = await getOrCreateBillingAccountForUser(
    accountService,
    {
      userId: input.sessionUser.id,
      ...(input.sessionUser.walletAddress
        ? { walletAddress: input.sessionUser.walletAddress }
        : {}),
    }
  );

  const caller: LlmCaller = {
    billingAccountId: billingAccount.id,
    virtualKeyId: billingAccount.defaultVirtualKeyId,
    requestId: ctx.reqId,
    traceId: ctx.traceId,
    userId: input.sessionUser.id,
    // Derive sessionId from stateKey for Langfuse session grouping
    // Hash ensures deterministic, bounded, log-safe output; truncation at sink
    ...(input.stateKey && {
      sessionId: deriveSessionId(billingAccount.id, input.stateKey),
    }),
  };

  const enrichedCtx: RequestContext = {
    ...ctx,
    log: ctx.log.child({
      userId: input.sessionUser.id,
      billingAccountId: billingAccount.id,
    }),
  };

  const timestamp = clock.now();
  const coreMessages = toCoreMessages(input.messages, timestamp);

  // Per CREDITS_ENFORCED_AT_EXECUTION_PORT: preflight credit check is handled
  // by PreflightCreditCheckDecorator inside the graph executor stack.
  // No facade-level preflightCreditCheck() call needed.

  const aiRuntime = createAiRuntime({ graphExecutor });

  // runChatStream is now synchronous (returns immediately with stream handle)
  const { stream, final } = aiRuntime.runChatStream(
    {
      messages: coreMessages,
      model: input.model,
      caller,
      ...(input.abortSignal ? { abortSignal: input.abortSignal } : {}),
      graphName: input.graphName,
      ...(input.stateKey ? { stateKey: input.stateKey } : {}),
    },
    enrichedCtx
  );

  return { stream, final };
}
