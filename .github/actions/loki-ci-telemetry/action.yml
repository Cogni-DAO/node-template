# SPDX-License-Identifier: LicenseRef-PolyForm-Shield-1.0.0
# SPDX-FileCopyrightText: 2025 Cogni-DAO

name: CI Telemetry to Loki
description: |
  Capture CI job telemetry and push to Grafana Cloud Loki.
  - Always: writes JSON summary (queryable via {env="ci"} | json)
  - On failure: appends generic failure context (job logs, metadata)
  - On failure + compose_file: appends docker/compose logs
  - Always: pushes to Loki with env=ci label and low-cardinality labels

inputs:
  loki_url:
    description: "Grafana Cloud Loki push URL"
    required: true
  loki_user:
    description: "Loki basic auth username (numeric user ID)"
    required: true
  loki_token:
    description: "Loki basic auth API key"
    required: true
  job_status:
    description: "Job status from caller (pass job.status from workflow)"
    required: true
  compose_file:
    description: "Path to docker-compose file for failure context (optional)"
    required: false
  compose_services:
    description: "Space-separated services to capture logs from"
    required: false
    default: "app litellm caddy postgres alloy db-provision db-migrate"
  tail_lines:
    description: "Number of log lines to capture per service on failure"
    required: false
    default: "200"

runs:
  using: composite
  steps:
    - name: Capture run summary
      if: always()
      shell: bash
      run: |
        # JSON summary for all runs (success + failure) - always first line (NDJSON)
        LOG_FILE="${{ runner.temp }}/ci-job.log"
        SHA8="${{ github.sha }}"
        SHA8="${SHA8:0:8}"

        # Validate job_status input (composite actions can't access job.status directly)
        # Allowed: success, failure, cancelled, skipped
        STATUS="${{ inputs.job_status }}"
        case "$STATUS" in
          success|failure|cancelled|skipped) ;;
          *) STATUS="unknown" ;;
        esac

        jq -nc \
          --arg type "ci_run_summary" \
          --arg status "$STATUS" \
          --arg workflow "${{ github.workflow }}" \
          --arg job "${{ github.job }}" \
          --arg run_id "${{ github.run_id }}" \
          --arg attempt "${{ github.run_attempt }}" \
          --arg ref "${{ github.ref_name }}" \
          --arg sha "${{ github.sha }}" \
          --arg sha8 "$SHA8" \
          --arg actor "${{ github.actor }}" \
          --arg repo "${{ github.repository }}" \
          --arg run_url "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}" \
          --arg captured_at "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
          '{schema_version: 1, type: $type, status: $status, workflow: $workflow, job: $job, run_id: $run_id, attempt: $attempt, ref: $ref, sha: $sha, sha8: $sha8, actor: $actor, repo: $repo, run_url: $run_url, captured_at: $captured_at}' \
          >> "$LOG_FILE"

        printf '\n' >> "$LOG_FILE"

    - name: Capture generic failure context
      if: failure()
      shell: bash
      env:
        GITHUB_TOKEN: ${{ github.token }}
      run: |
        LOG_FILE="${{ runner.temp }}/ci-job.log"
        MAX_GENERIC_BYTES=262144  # 256KB cap for generic failure context

        # Temp file for generic context
        TEMP_GENERIC=$(mktemp)
        trap "rm -f '$TEMP_GENERIC'" EXIT

        {
          echo ""
          echo "=== Generic Failure Context ==="
          echo "captured_at: $(date -u +%Y-%m-%dT%H:%M:%SZ)"
          echo "workflow: ${{ github.workflow }}"
          echo "job: ${{ github.job }}"
          echo "run_id: ${{ github.run_id }}"
          echo "run_attempt: ${{ github.run_attempt }}"
          echo "ref: ${{ github.ref_name }}"
          echo "sha: ${{ github.sha }}"
          echo "actor: ${{ github.actor }}"
          echo "runner_os: ${{ runner.os }}"
          echo "runner_name: ${{ runner.name }}"

          # Toolchain versions
          echo ""
          echo "=== Toolchain Versions ==="
          node --version 2>&1 || echo "node: not found"
          pnpm --version 2>&1 || echo "pnpm: not found"
          git --version 2>&1 || echo "git: not found"
          docker --version 2>&1 || echo "docker: not found"

          # Repo state
          echo ""
          echo "=== Repo State ==="
          git status --porcelain 2>&1 || echo "git status failed"

          # Debug files (if present and small)
          if [[ -f "pnpm-debug.log" ]] && [[ $(wc -c < "pnpm-debug.log") -lt 10240 ]]; then
            echo ""
            echo "=== pnpm-debug.log ==="
            cat pnpm-debug.log
          fi

        } > "$TEMP_GENERIC"

        # Fetch GitHub Actions job logs via API
        TEMP_JOB_LOGS=$(mktemp)
        trap "rm -f '$TEMP_GENERIC' '$TEMP_JOB_LOGS'" EXIT

        OUTPUT_FILE="$TEMP_JOB_LOGS" \
          GITHUB_TOKEN="$GITHUB_TOKEN" \
          GITHUB_REPOSITORY="${{ github.repository }}" \
          GITHUB_RUN_ID="${{ github.run_id }}" \
          GITHUB_RUN_ATTEMPT="${{ github.run_attempt }}" \
          GITHUB_JOB="${{ github.job }}" \
          platform/ci/scripts/fetch_github_job_logs.sh || true

        # Append job logs to generic context
        cat "$TEMP_JOB_LOGS" >> "$TEMP_GENERIC"

        # Cap size and prefix with FAILCTX:
        head -c "$MAX_GENERIC_BYTES" "$TEMP_GENERIC" | sed 's/^/FAILCTX: /' >> "$LOG_FILE"

    - name: Capture docker-compose failure context
      if: failure() && inputs.compose_file != ''
      shell: bash
      env:
        COMPOSE_FILE: ${{ inputs.compose_file }}
        COMPOSE_SERVICES: ${{ inputs.compose_services }}
        TAIL_LINES: ${{ inputs.tail_lines }}
      run: |
        LOG_FILE="${{ runner.temp }}/ci-job.log"
        MAX_FAILCTX_BYTES=524288  # 512KB cap for docker-compose context

        # Capture to temp file first, then prefix and append
        TEMP_FAILCTX=$(mktemp)
        trap "rm -f '$TEMP_FAILCTX'" EXIT

        {
          echo ""
          echo "=== Docker-Compose Failure Context ==="
          echo "captured_at: $(date -u +%Y-%m-%dT%H:%M:%SZ)"

          # Docker system state
          echo ""
          echo "=== docker ps ==="
          docker ps -a --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}" 2>&1 || echo "docker ps failed"

          # Compose state (if project exists)
          if docker compose -f "$COMPOSE_FILE" ps --quiet 2>/dev/null; then
            echo ""
            echo "=== docker compose ps ==="
            docker compose -f "$COMPOSE_FILE" ps 2>&1 || true

            # Capture logs for each service
            for svc in $COMPOSE_SERVICES; do
              echo ""
              echo "=== logs: $svc (tail $TAIL_LINES) ==="
              docker compose -f "$COMPOSE_FILE" logs --tail="$TAIL_LINES" "$svc" 2>&1 || echo "No logs for $svc"
            done
          else
            echo "No compose project found for $COMPOSE_FILE"
          fi
        } > "$TEMP_FAILCTX"

        # Cap size and prefix with FAILCTX:
        # Note: byte-cap (head -c) can cut mid-line, producing messy output.
        # MVP accepts this; future: use line-based cap (awk/perl) for cleaner truncation.
        head -c "$MAX_FAILCTX_BYTES" "$TEMP_FAILCTX" | sed 's/^/FAILCTX: /' >> "$LOG_FILE"

    - name: Push to Loki
      if: always()
      uses: ./.github/actions/loki-push
      with:
        loki_url: ${{ inputs.loki_url }}
        loki_user: ${{ inputs.loki_user }}
        loki_token: ${{ inputs.loki_token }}
        log_file: ${{ runner.temp }}/ci-job.log
        job_name: ${{ github.job }}
        labels: workflow=${{ github.workflow }} ref=${{ github.ref_name }} run_id=${{ github.run_id }} attempt=${{ github.run_attempt }} sha8=${{ github.sha }} status=${{ inputs.job_status }}
