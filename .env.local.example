# Development Environment Variables
# Copy this to .env.local (never commit .env.local)

# Node environment
NODE_ENV=development

# Application environment (controls adapter wiring)
APP_ENV=production
# APP_ENV=test  # Uncomment to use fake adapters locally (CI sets this automatically)

# App runtime (used by Next.js server/runtime only)
APP_BASE_URL=http://localhost:3000
NEXTAUTH_URL=http://localhost:3000
DOMAIN=localhost

# Database - PostgreSQL Docker service configuration (for docker compose)
POSTGRES_DB=cogni_template_dev
POSTGRES_USER=user
POSTGRES_PASSWORD=password
DB_HOST=localhost
DB_PORT=55432
DATABASE_URL="postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${DB_HOST}:${DB_PORT}/${POSTGRES_DB}"

# Auth.js (NextAuth) - Required for authentication
# Generate with: openssl rand -base64 32
AUTH_SECRET="local-dev-secret-at-least-32-characters-long-change-me"

# LLM Integration (Stage 8) - LITELLM_BASE_URL auto-detects based on NODE_ENV
# Default models are computed from LiteLLM catalog metadata (metadata.cogni.default_preferred/default_free)
LITELLM_BASE_URL=http://localhost:4000
LITELLM_MASTER_KEY=your-litellm-master-key-here
OPENROUTER_API_KEY=your-openrouter-api-key-here

# LangGraph Dev Server (Optional)
# Set to enable langgraph dev server execution instead of in-process.
# Start server with: pnpm langgraph:dev
# Default port for langgraph dev: 2024
# LANGGRAPH_DEV_URL=http://localhost:2024

# Temporal Schedule Orchestration (required)
# App requires Temporal - start with: pnpm dev:infra
# Use localhost for host-mode dev (pnpm dev); docker-compose overrides for container-mode
TEMPORAL_ADDRESS=localhost:7233
TEMPORAL_NAMESPACE=cogni-production
TEMPORAL_TASK_QUEUE=scheduler-tasks

# Temporal DB (compose-only, app never uses these):
# TEMPORAL_DB_HOST=temporal-postgres
# TEMPORAL_DB_PORT=5432
# TEMPORAL_DB_USER=temporal
# TEMPORAL_DB_PASSWORD=temporal

# LangSmith API Key (only for langgraph dev server, not loaded by Next.js)
# Required by LangGraph Studio/dev server for tracing.
# Get from: https://smith.langchain.com → Settings → API Keys
# LANGSMITH_API_KEY=lsv2_pt_your-api-key-here

# Optional server config
PORT=3000
PINO_LOG_LEVEL=debug

# Observability - Log Collection (Alloy → Loki)
# For local dev: Uses local Loki (no cloud credentials needed, auto-configured by docker-compose.dev.yml)
# DEPLOY_ENVIRONMENT=local  # Auto-set by docker-compose.dev.yml, no need to define
# LOKI_WRITE_URL=http://loki:3100/loki/api/v1/push  # Auto-set by docker-compose.dev.yml
# LOKI_USERNAME=  # Empty for local dev (auto-set by docker-compose.dev.yml)
# LOKI_PASSWORD=  # Empty for local dev (auto-set by docker-compose.dev.yml)

# Optional: Override to send local logs to Grafana Cloud instead (not recommended for dev)
# DEPLOY_ENVIRONMENT=local
# LOKI_WRITE_URL="https://logs-prod-020.grafana.net/loki/api/v1/push"
# LOKI_USERNAME="123456"  # Your numeric user ID
# LOKI_PASSWORD="glc_your_api_key_here"  # API key with logs:write permission

# Observability - Prometheus Metrics (Stage 9)
# Token for /api/metrics endpoint authentication (min 32 chars, required in production)
METRICS_TOKEN=local-dev-metrics-token-32chars!

# Scheduler API token - auth for scheduler-worker → internal graph execution API
# Used by scheduler-worker to call POST /api/internal/graphs/{graphId}/runs
# Required: min 32 chars. Generate with: openssl rand -base64 32
SCHEDULER_API_TOKEN=local-dev-scheduler-api-token-min32chars

# Scheduler worker app URL - how the scheduler-worker (in Docker) reaches the app
# For pnpm dev:stack (app runs natively on host): use host.docker.internal
# For pnpm docker:stack (app runs in Docker): leave unset (defaults to http://app:3000)
SCHEDULER_APP_BASE_URL=http://host.docker.internal:3000

# Optional: Prometheus metrics (Grafana Cloud)
# WRITE path (Alloy remote_write) - write-only token
# PROMETHEUS_REMOTE_WRITE_URL="https://prometheus-prod-37-prod-ap-southeast-1.grafana.net/api/prom/push"
# PROMETHEUS_USERNAME="123456"  # Your numeric user ID
# PROMETHEUS_PASSWORD="glc_write_token_here"  # API key with metrics:write ONLY

# READ path (app queries) - read-only token (separate from write for least privilege)
# PROMETHEUS_QUERY_URL is auto-derived from PROMETHEUS_REMOTE_WRITE_URL (strips /push)
# PROMETHEUS_READ_USERNAME="123456"  # Same user ID is fine
# PROMETHEUS_READ_PASSWORD="glc_..."  # Create at https://grafana.com/orgs/<org>/access-policies → metrics:read scope

# Grafana MCP (for Agentic log queries)
# For local dev: Use grafana-local MCP server (connects to http://localhost:3001)
# For cloud queries: Use grafana MCP server with credentials below
GRAFANA_URL="https://your-org.grafana.net"
GRAFANA_SERVICE_ACCOUNT_TOKEN="glsa_your_service_account_token_here"  # Generate at: Grafana → Administration → Service accounts → Add token

# Langfuse - AI Observability (Optional)
# When set, AI completions are traced to Langfuse for debugging and eval.
# Get keys from: https://cloud.langfuse.com → Settings → API Keys
# LANGFUSE_PUBLIC_KEY=pk-lf-your-public-key
# LANGFUSE_SECRET_KEY=sk-lf-your-secret-key
# LANGFUSE_BASE_URL=https://cloud.langfuse.com  # Optional, defaults to cloud. Use for self-hosted.

# EVM RPC - On-chain verification (Base mainnet)
# Get free API key from: alchemy.com or infura.io
EVM_RPC_URL=https://base-mainnet.g.alchemy.com/v2/your-api-key-here

# Public client vars
# Wallet Integration
NEXT_PUBLIC_WALLETCONNECT_PROJECT_ID=get-from-walletconnect-cloud  # Get from cloud.walletconnect.com

# Crypto widget payments (DePay) - crypto-only credits
# DAO receiving wallet + chain come from .cogni/repo-spec.yaml (no env override)

# Development tokens (replace with your own)
CHERRY_AUTH_KEY=your-cherry-auth-key-here
CR_PAT=your-github-pat-here

# Brain repo access (required — no default, no silent cwd fallback)
# "." = local checkout for pnpm dev. See docs/COGNI_BRAIN_SPEC.md "Repo Access Modes".
COGNI_REPO_PATH=.

# git-sync (required for all docker workflows: dev:infra, docker:dev:stack, docker:stack)
# The git-sync container clones the repo into a shared volume; the app reads /repo/current.
# Fine-grained PAT: Contents:Read scope, scoped to this repo (public repos work without token)
COGNI_REPO_URL=https://github.com/Cogni-DAO/node-template.git
COGNI_REPO_REF=HEAD
GIT_READ_USERNAME=your-github-username
GIT_READ_TOKEN=your-fine-grained-pat-here

# Test Environment Configuration
# Used by API integration tests in tests/api/**

# For dev:stack (Next.js runs locally, containers provide infrastructure)
TEST_BASE_URL=http://localhost:3000/

# For docker:stack (everything in containers, accessible via Caddy)
# TEST_BASE_URL=https://localhost/

# Remote environments
# TEST_BASE_URL=https://your-domain.com/

# Billing Evolution Stage 6.5
USER_PRICE_MARKUP_FACTOR=2.0

## Required for Production simulation of Docker (docker:stack:setup)
# Root DB credentials
POSTGRES_ROOT_USER=postgres
POSTGRES_ROOT_PASSWORD=postgres

# App DB credentials (same as root for local testing. Production security boundary not needed)
APP_DB_NAME=cogni_template_dev
APP_DB_USER=postgres
APP_DB_PASSWORD=postgres
